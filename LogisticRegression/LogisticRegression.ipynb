{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# __future__ imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import two best libraries :D\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download training data from http://download.tensorflow.org/data/iris_training.csv\n",
    "# Download testing data from http://download.tensorflow.org/data/iris_test.csv\n",
    "iris_training = \"iris_training.csv\"\n",
    "iris_testing = \"iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data from csv. Data will be loaded in tensorflow Dataset format.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "                filename = iris_training,\n",
    "                target_dtype = np.int,\n",
    "                features_dtype = np.float32)\n",
    "testing_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "                filename = iris_testing,\n",
    "                target_dtype = np.int,\n",
    "                features_dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since we have three classes, we will merge class = 1 and class = 2. \n",
    "# So, now we will have binary classification problem (0, 1)\n",
    "\n",
    "X_train_data = training_set.data\n",
    "Y_train = training_set.target\n",
    "Y_train[Y_train > 1] = 1\n",
    "\n",
    "X_test_data = testing_set.data\n",
    "Y_test = testing_set.target\n",
    "Y_test[Y_test > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf.placeholder is used for data\n",
    "X = tf.placeholder(tf.float32, shape = [None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.Variable is used for Variable\n",
    "W = tf.Variable(tf.random_normal([4,1]), name=\"weights\" )\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's assume hypothesis. We are assuming function\n",
    "#      Y = W * X + b\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use categorical cross entropy loss (or cost)\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y)*tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will define an optimizer (Gradient Descent Optimizer)\n",
    "# learning_rate = 0.001 and we will use it to minimize cost\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate= 0.001)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict if output probability > 0.5\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype= tf.float32)\n",
    "\n",
    "#Define accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.3275 0.35\n",
      "1000 0.763835 0.59\n",
      "2000 0.70735 0.6125\n",
      "3000 0.676815 0.635\n",
      "4000 0.662602 0.6475\n",
      "5000 0.656595 0.6475\n",
      "6000 0.654172 0.6475\n",
      "7000 0.653213 0.6475\n",
      "8000 0.652818 0.6475\n",
      "9000 0.652646 0.65\n",
      "10000 0.652551 0.65\n",
      "11000 0.652492 0.65\n",
      "12000 0.652438 0.65\n",
      "13000 0.652395 0.65\n",
      "14000 0.65235 0.65\n",
      "15000 0.652316 0.65\n",
      "16000 0.652272 0.65\n",
      "17000 0.65223 0.65\n",
      "18000 0.652189 0.65\n",
      "19000 0.65215 0.65\n"
     ]
    }
   ],
   "source": [
    "#create a new session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize all the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "# train for 20000 epochs\n",
    "for epoch in range(20000):\n",
    "        \n",
    "    cost_val, acc_val, _ = sess.run([cost,accuracy, train], feed_dict = {X : X_train_data, Y : Y_train})\n",
    "        \n",
    "    if(epoch % 1000 == 0):\n",
    "        print(epoch, cost_val, acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, acc_test = sess.run([predicted, accuracy], feed_dict = {X: X_test_data, Y: Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is  0.733333\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy is \", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we are getting the same accuracy in sklearn logistic regression also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a logistic regression\n",
    "# We will use very small C value because we are not adding any penalty\n",
    "logistic_regression = LogisticRegression(max_iter=20000, C = 1e-9, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e-09, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=20000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on training data\n",
    "logistic_regression.fit(X_train_data, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy using sklearn is  0.733333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy using sklearn is \", logistic_regression.score(X_test_data, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yeah! We did it right in our tensor flow logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and add regularization term in our logistic regression tensor flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost2 = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y)*tf.log(1 - hypothesis)) + tf.reduce_sum(tf.square(W))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer2 = tf.train.GradientDescentOptimizer(learning_rate= 0.001)\n",
    "train2 = optimizer2.minimize(cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted2 = tf.cast(hypothesis > 0.5, dtype= tf.float32)\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.8765 0.35\n",
      "1000 0.648193 0.65\n",
      "2000 0.648045 0.65\n",
      "3000 0.647981 0.65\n",
      "4000 0.647944 0.65\n",
      "5000 0.647928 0.65\n",
      "6000 0.647914 0.65\n",
      "7000 0.647903 0.65\n",
      "8000 0.647887 0.65\n",
      "9000 0.647879 0.65\n",
      "10000 0.647868 0.65\n",
      "11000 0.647854 0.65\n",
      "12000 0.64785 0.65\n",
      "13000 0.647835 0.65\n",
      "14000 0.647826 0.65\n",
      "15000 0.64782 0.65\n",
      "16000 0.647808 0.65\n",
      "17000 0.6478 0.65\n",
      "18000 0.647793 0.65\n",
      "19000 0.647784 0.65\n"
     ]
    }
   ],
   "source": [
    "sess2 = tf.Session()\n",
    "\n",
    "sess2.run(tf.global_variables_initializer())\n",
    "    \n",
    "for steps in range(20000):\n",
    "        \n",
    "    cost_val, acc_val, _ = sess2.run([cost,accuracy, train], feed_dict = {X : X_train_data, Y : Y_train})\n",
    "        \n",
    "    if(steps % 1000 == 0):\n",
    "        print(steps, cost_val, acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, acc_test2 = sess.run([predicted, accuracy], feed_dict = {X: X_test_data, Y: Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with regularization is  0.733333\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy with regularization is \", acc_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope regularization does not improve our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
